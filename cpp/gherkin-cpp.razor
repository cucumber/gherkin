@using Berp;
@functions {
public static string ToSnakeCase(string str)
{
    return
        string.Concat(
            str.Select(
                (x, i) => i > 0 && char.IsUpper(x)
                ? "_" + x
                : x.ToString()
            )
        ).ToLower();
}

public static string NameOf(Rule rule)
{ return ToSnakeCase(rule.Name.Replace("#", "")); }
}
@helper CallProduction(ProductionRule production)
{
  switch(production.Type)
  {
    case ProductionRuleType.Start:
      @:  start_rule(context, Rule_@production.RuleName);
      break;
    case ProductionRuleType.End:
      @:  end_rule(context, Rule_@production.RuleName);
      break;
    case ProductionRuleType.Process:
      @:  build(context, token);
      break;
  }
}
@helper HandleParserError(IEnumerable<string> expectedTokens, State state)
{<text>
    /* "State: @state.Id - @Raw(state.Comment)" */
    std::string expected_tokens = L"@Raw(string.Join(", ", expectedTokens))";

    auto error =
        token.is_eof()
        ? error_type::unexpected_eof
        : error_type::unexpected_token
        ;

    if (stop_at_first_error()) {
        throw_error(error, token, expected_tokens);
    }

    add_error(error, token, expected_tokens);

    return @state.Id;</text>}
@helper MatchToken(TokenType tokenType)
{<text>match_@(tokenType)(context, token)</text>}
// This file is generated. Do not edit! Edit gherkin-cpp-parser.razor instead.
#include <gherkin/parser.hpp>
#include <gherkin/parser_context.hpp>
#include <gherkin/token_scanner.hpp>
#include <gherkin/rule_type.hpp>

namespace gherkin {

parser::parser(const parser_info& pi)
: pi_{pi}
{}

std::size_t
parser::parse(const file& file)
{
    ast_builder_.reset();
    token_scanner_.reset();
    token_matcher_.reset();

    parser_context context{
        .token_scanner = token_scanner_,
        .token_matcher = token_matcher_
    };

    start_rule(context, rule_type::@NameOf(Model.RuleSet.StartRule));

    std::size_t state = 0;

    while (true) {
        auto token = read_token(context);
        state = match_token(state, token, context);

        if (token.is_eof()) {
            break;
        }
    }

    end_rule(context, rule_type::@NameOf(Model.RuleSet.StartRule));

    if (context.has_errors()) {
        // TODO: thow coumpound error
    }

    return get_result();
}

std::size_t
parser::match_token(std::size_t state, token& token, parser_context& context)
{
    return state;
}

token
parser::read_token(parser_context& context)
{
    token t;

    if (context.has_token()) {
        t = context.pop_token();
    } else {
        t = context.token_scanner.read();
    }

    return t;
}

std::size_t
parser::get_result() const
{ return 0; }

namespace detail {

void
handle_ast_error(parser_context& context)
{}

@foreach(var rule in Model.RuleSet.TokenRules)
{
<text>
bool
match_@(NameOf(rule))(parser_context& context, token& token)
{
    @if (rule.Name != "#EOF")
    {
    @:if (token.eof()) {
    @:    return false;
    @:}
    @:
    }
    return
        handle_external_error(
            context,
            false,
            token,
            context.token_matcher.match_@(NameOf(rule))
        );
}
</text>
}

parser::match_token(parser_context& context, token& token)
{
    state_map = {
    @foreach(var state in Model.States.Values.Where(s => !s.IsEndState))
    {
    @:    @state.Id: self.match_token_at_@(state.Id),
    }
    }
    if state in state_map:
        return state_map[state](token, context)
    else:
        raise RuntimeError("Unknown state: " + str(state))
}

@foreach(var state in Model.States.Values.Where(s => !s.IsEndState))
{<text>
// @Raw(state.Comment)
std::size_t
match_token_at_@(state.Id)(parser& parser, token& token, parser_context& context)
{
@{var indent = "";}
    @foreach(var transition in state.Transitions)
    {
    @:if (@MatchToken(transition.TokenType)) {
        if (transition.LookAheadHint != null)
        {
        @:if (lookahead_@(transition.LookAheadHint.Id)(context, token)) {
            indent = "    ";
        }
        foreach(var production in transition.Productions)
        {
            @indent@CallProduction(production)
        }
        @:@(indent)return transition.TargetState;
        if (transition.LookAheadHint != null)
        {
        @:}
        }
    @:}
    }

    @HandleParserError(state.Transitions.Select(t => "#" + t.TokenType.ToString()).Distinct(), state)
}
</text>
}

@foreach(var lookAheadHint in Model.RuleSet.LookAheadHints)
{
<text>
bool
lookahead_@(lookAheadHint.Id)(parser_context& context, token& current_token)
{
    current_token.detach();
    token token;
    token_queue queue;
    bool match = false;

    while (true) {
        token = context.read_token();
        token.detach()
        queue.push_back(token);

        if (@foreach(var tokenType in lookAheadHint.ExpectedTokens) {<text>s@MatchToken(tokenType) || </text>}false) {
            match = true;
            break;
        }

        if not (@foreach(var tokenType in lookAheadHint.Skip) {<text>@MatchToken(tokenType) || </text>}false) {
            break;
        }

        context.push_tokens(queue);

        return match;
}</text>
}

void
handle_ast_error(parser_context& context, token& token, match_function action)
{ handle_external_error(context, true, token, action); }

bool
handle_external_error(
    parser_context& context,
    bool default_value,
    token& token,
    match_function action
)
{
    if (context.stop_at_first_error) {
        return action(token);
    }

    try {
        return action(token);
    } catch (const std::exception& e) {
        add_error(context, e);
    }

    return default_value;
}

} // namespace detail
