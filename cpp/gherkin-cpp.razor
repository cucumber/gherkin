@using Berp;
@functions {
public static string ToSnakeCase(string str)
{
    return
        string.Concat(
            str.Select(
                (x, i) => i > 0 && char.IsUpper(x)
                ? "_" + x
                : x.ToString()
            )
        ).ToLower();
}

public static string NameOf(Rule rule)
{ return ToSnakeCase(rule.Name.Replace("#", "")); }
}
@helper CallProduction(ProductionRule production)
{
  var rname = ToSnakeCase(production.RuleName);

  switch(production.Type)
  {
    case ProductionRuleType.Start:
      @:  start_rule(context, rule_type::@rname);
      break;
    case ProductionRuleType.End:
      @:  end_rule(context, rule_type::@rname);
      break;
    case ProductionRuleType.Process:
      @:  build(context, token);
      break;
  }
}
@helper HandleParserError(IEnumerable<string> expectedTokens, State state)
{<text>
    /* "State: @state.Id - @Raw(state.Comment)" */
    std::string expected_tokens = "@Raw(string.Join(", ", expectedTokens))";

    auto error =
        token.is_eof()
        ? error_type::unexpected_eof
        : error_type::unexpected_token
        ;

    if (context.stop_at_first_error) {
        //throw_error(error, token, expected_tokens);
    }

    context.add_error(expected_tokens);

    return @state.Id;</text>}
@helper MatchToken(TokenType tokenType)
{<text>match_@(ToSnakeCase(tokenType.Name))(context, token)</text>}
// This file is generated. Do not edit! Edit gherkin-cpp-parser.razor instead.
#include <functional>

#include <gherkin/parser.hpp>
#include <gherkin/token.hpp>
#include <gherkin/rule_type.hpp>
#include <gherkin/types.hpp>

namespace gherkin {

struct parser_context
{
    ast_builder& builder;
    token_scanner& scanner;
    token_matcher& matcher;
    token_queue queue;
    strings errors;
    bool stop_at_first_error = false;

    bool has_token() const
    { return !queue.empty(); }

    token pop_token()
    {
        auto t = std::move(queue.front());
        queue.pop_front();

        return t;
    }

    token read_token()
    { return has_token() ? pop_token() : scanner.read(); }

    void push_tokens(const token_queue& q)
    { queue.insert(queue.end(), q.begin(), q.end()); }

    bool has_errors() const
    { return !errors.empty(); }

    void add_error(const std::string& e)
    { errors.push_back(e); }

    void add_error(const std::exception& e)
    { add_error(e.what()); }
};

enum class error_type
{
    unexpected_eof,
    unexpected_token
};

using match_function = std::function<std::size_t(parser_context&, token&)>;
using match_functions = std::unordered_map<std::size_t, match_function>;

static void start_rule(parser_context& context, rule_type rule_type);

static void end_rule(parser_context& context, rule_type rule_type);

static std::size_t match_token(
    std::size_t state,
    token& token,
    parser_context& context
);

template <typename Argument, typename Action>
bool
handle_external_error(
    parser_context& context,
    bool default_value,
    Argument&& argument,
    Action&& action
)
{
    using ret_type = decltype(action(argument));

    if (context.stop_at_first_error) {
        if constexpr (std::is_same_v<ret_type, void>) {
            action(argument);
            return default_value;
        } else {
            return action(argument);
        }
    }

    try {
        if constexpr (std::is_same_v<ret_type, void>) {
            action(argument);
            return default_value;
        } else {
            return action(argument);
        }
    } catch (const std::exception& e) {
        context.add_error(e);
    }

    return default_value;
}

template <typename Argument, typename Action>
void
handle_ast_error(
    parser_context& context,
    Argument&& argument,
    Action&& action
)
{ handle_external_error(context, true, argument, action); }

parser::parser(const parser_info& pi)
: pi_{pi}
{}

std::size_t
parser::parse(const file& file)
{
    builder_.reset();
    scanner_.reset();
    matcher_.reset();

    parser_context context{
        .builder = builder_,
        .scanner = scanner_,
        .matcher = matcher_
    };

    start_rule(context, rule_type::@NameOf(Model.RuleSet.StartRule));

    std::size_t state = 0;

    while (true) {
        auto token = context.read_token();
        state = match_token(state, token, context);

        if (token.is_eof()) {
            break;
        }
    }

    end_rule(context, rule_type::@NameOf(Model.RuleSet.StartRule));

    if (context.has_errors()) {
        // TODO: thow coumpound error
    }

    return 0;
}

static
void
build(parser_context& context, token& token)
{ context.builder.build(token); }

static
void
start_rule(parser_context& context, rule_type rule_type)
{
    handle_ast_error(
        context,
        rule_type,
        [&context](auto rtype) {
            context.builder.start_rule(rtype);
        }
    );
}

static
void
end_rule(parser_context& context, rule_type rule_type)
{
    handle_ast_error(
        context,
        rule_type,
        [&context](auto rtype) {
            context.builder.end_rule(rtype);
        }
    );
}

namespace detail {

@foreach(var rule in Model.RuleSet.TokenRules)
{
<text>
static
bool
match_@(NameOf(rule))(parser_context& context, token& token)
{
    @if (rule.Name != "#EOF")
    {
    @:if (token.is_eof()) {
    @:    return false;
    @:}
    @:
    }
    return
        handle_external_error(
            context,
            false,
            token,
            [&context](auto& t) {
                return context.matcher.match_@(NameOf(rule))(t);
            }
        );
}
</text>
}

@foreach(var lookAheadHint in Model.RuleSet.LookAheadHints)
{
<text>
static
bool
lookahead_@(lookAheadHint.Id)(parser_context& context, token& current_token)
{
    current_token.detach();
    token token;
    token_queue queue;
    bool match = false;

    while (true) {
        token = context.read_token();
        token.detach();
        queue.push_back(token);

        if (@foreach(var tokenType in lookAheadHint.ExpectedTokens) {<text>@MatchToken(tokenType) || </text>}false) {
            match = true;
            break;
        }

        if (!(@foreach(var tokenType in lookAheadHint.Skip) {<text>@MatchToken(tokenType) || </text>}false)) {
            break;
        }
    }

    context.push_tokens(queue);

    return match;
}
</text>
}

@foreach(var state in Model.States.Values.Where(s => !s.IsEndState))
{<text>
// @Raw(state.Comment)
static
std::size_t
match_token_at_@(state.Id)(token& token, parser_context& context)
{
@{var indent = "";}
    @foreach(var transition in state.Transitions)
    {
    @:if (@MatchToken(transition.TokenType)) {
        if (transition.LookAheadHint != null)
        {
        @:if (lookahead_@(transition.LookAheadHint.Id)(context, token)) {
            indent = "    ";
        }
        foreach(var production in transition.Productions)
        {
            @indent@CallProduction(production)
        }
        @:@(indent)return @transition.TargetState;
        if (transition.LookAheadHint != null)
        {
        @:}
        }
    @:}
    }

    @HandleParserError(state.Transitions.Select(t => "#" + t.TokenType.ToString()).Distinct(), state)
}
</text>
}

} // namespace detail

static
std::size_t
match_token(std::size_t state, token& token, parser_context& context)
{
    switch (state) {
    @foreach(var state in Model.States.Values.Where(s => !s.IsEndState))
    {
    @:case @state.Id:
        @:return detail::match_token_at_@(state.Id)(token, context);
    }
    default:
        context.add_error("invalid operation: " + std::to_string(state));
        return -1;
    }
}

}
